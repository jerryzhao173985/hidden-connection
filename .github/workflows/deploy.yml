# Deploy static content to GitHub Pages
# Optionally regenerates embeddings using OpenAI API if OPENAI_API_KEY is set
name: Deploy to GitHub Pages

on:
  # Runs on pushes targeting the default branch
  push:
    branches: ["main"]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      regenerate_embeddings:
        description: 'Regenerate embeddings using OpenAI API'
        required: false
        default: 'false'
        type: boolean

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Optional: Process data with OpenAI embeddings
  process:
    runs-on: ubuntu-latest
    # Only run if manually triggered with regenerate_embeddings=true
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.regenerate_embeddings == 'true'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check for OpenAI API Key
        id: check_key
        run: |
          if [ -n "${{ secrets.OPENAI_API_KEY }}" ]; then
            echo "has_key=true" >> $GITHUB_OUTPUT
          else
            echo "has_key=false" >> $GITHUB_OUTPUT
            echo "::warning::OPENAI_API_KEY not set. Skipping embedding generation."
          fi

      - name: Setup Python
        if: steps.check_key.outputs.has_key == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        if: steps.check_key.outputs.has_key == 'true'
        run: |
          pip install numpy pandas scikit-learn umap-learn pyyaml openai

      - name: Run embedding pipeline
        if: steps.check_key.outputs.has_key == 'true'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          cd pipeline
          python process.py --config config.yaml
          echo "Pipeline completed successfully"

      - name: Upload processed data
        if: steps.check_key.outputs.has_key == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: web/points.json
          retention-days: 1

  # Deploy to GitHub Pages
  deploy:
    needs: [process]
    # Run even if process job was skipped
    if: always()
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download processed data
        # Only download if the process job ran and succeeded
        if: needs.process.result == 'success'
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: web/

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          # Upload the web directory
          path: './web'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
